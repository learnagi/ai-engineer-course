---
title: "å¯è§†åŒ–ä¸ç›‘æ§"
slug: "visualization-monitoring"
sequence: 6
description: "AIå¼€å‘ä¸­çš„æ•°æ®å¯è§†åŒ–å’Œæ¨¡å‹ç›‘æ§æŠ€æœ¯ï¼ŒåŒ…æ‹¬é™æ€å¯è§†åŒ–ã€äº¤äº’å¼å¯è§†åŒ–å’Œå®éªŒç›‘æ§"
is_published: true
estimated_minutes: 75
language: "zh-CN"
---

# å¯è§†åŒ–ä¸ç›‘æ§

## è¯¾ç¨‹ä»‹ç»
æœ¬æ¨¡å—èšç„¦AIå¼€å‘ä¸­çš„å¯è§†åŒ–å’Œç›‘æ§æŠ€æœ¯ï¼Œæ•™ä½ å¦‚ä½•åˆ›å»ºç›´è§‚çš„æ•°æ®å¯è§†åŒ–å’Œæœ‰æ•ˆçš„æ¨¡å‹ç›‘æ§ç³»ç»Ÿã€‚é€šè¿‡å®é™…æ¡ˆä¾‹ï¼ŒæŒæ¡ä»åŸºç¡€å›¾è¡¨åˆ°äº¤äº’å¼ä»ªè¡¨æ¿çš„å¼€å‘æŠ€èƒ½ã€‚

## å­¦ä¹ ç›®æ ‡
å®Œæˆæœ¬æ¨¡å—å­¦ä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š
- ä½¿ç”¨å¤šç§å·¥å…·åˆ›å»ºæ•°æ®å¯è§†åŒ–
- å¼€å‘äº¤äº’å¼å¯è§†åŒ–ä»ªè¡¨æ¿
- æ„å»ºæ¨¡å‹è®­ç»ƒç›‘æ§ç³»ç»Ÿ
- è®¾è®¡å®éªŒè·Ÿè¸ªå¹³å°

## 1. é™æ€å¯è§†åŒ–

### 1.1 MatplotlibåŸºç¡€
```python
# ğŸ“Š å®æˆ˜æ¡ˆä¾‹ï¼šæ¨¡å‹è¯„ä¼°å¯è§†åŒ–
import matplotlib.pyplot as plt
import numpy as np

def plot_model_evaluation(y_true, y_pred):
    """åˆ›å»ºæ¨¡å‹è¯„ä¼°å¯è§†åŒ–"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. é¢„æµ‹vså®é™…å€¼æ•£ç‚¹å›¾
    axes[0,0].scatter(y_true, y_pred, alpha=0.5)
    axes[0,0].plot([y_true.min(), y_true.max()], 
                   [y_true.min(), y_true.max()], 
                   'r--', lw=2)
    axes[0,0].set_title('é¢„æµ‹ vs å®é™…å€¼')
    
    # 2. æ®‹å·®å›¾
    residuals = y_pred - y_true
    axes[0,1].hist(residuals, bins=30)
    axes[0,1].set_title('æ®‹å·®åˆ†å¸ƒ')
    
    # 3. é¢„æµ‹å€¼çš„ç½®ä¿¡åŒºé—´
    sorted_idx = np.argsort(y_true)
    axes[1,0].plot(y_true[sorted_idx], label='å®é™…å€¼')
    axes[1,0].fill_between(range(len(y_true)), 
                          y_pred[sorted_idx] - residuals.std(),
                          y_pred[sorted_idx] + residuals.std(),
                          alpha=0.3)
    axes[1,0].set_title('é¢„æµ‹ç½®ä¿¡åŒºé—´')
    
    # 4. Q-Qå›¾
    from scipy import stats
    stats.probplot(residuals, dist="norm", plot=axes[1,1])
    axes[1,1].set_title('Q-Qå›¾')
    
    plt.tight_layout()
    return fig
```

### 1.2 Seabornè¿›é˜¶
```python
# ğŸ¨ å®æˆ˜æ¡ˆä¾‹ï¼šç‰¹å¾åˆ†æå¯è§†åŒ–
import seaborn as sns

def plot_feature_analysis(df, target_col):
    """åˆ›å»ºç‰¹å¾åˆ†æå¯è§†åŒ–"""
    # è®¾ç½®é£æ ¼
    sns.set_style("whitegrid")
    sns.set_palette("husl")
    
    # åˆ›å»ºå›¾è¡¨
    g = sns.PairGrid(df, hue=target_col, 
                     diag_kind="hist", 
                     corner=True)
    
    # æ·»åŠ ä¸åŒç±»å‹çš„å›¾
    g.map_lower(sns.scatterplot, alpha=0.5)
    g.map_diag(sns.histplot, multiple="stack")
    
    # æ·»åŠ å›¾ä¾‹
    g.add_legend()
    
    return g.fig

def plot_correlation_matrix(df):
    """åˆ›å»ºç›¸å…³æ€§çŸ©é˜µçƒ­å›¾"""
    plt.figure(figsize=(12, 8))
    
    # è®¡ç®—ç›¸å…³æ€§
    corr = df.corr()
    
    # åˆ›å»ºæ©ç ï¼ˆåªæ˜¾ç¤ºä¸Šä¸‰è§’ï¼‰
    mask = np.triu(np.ones_like(corr, dtype=bool))
    
    # ç»˜åˆ¶çƒ­å›¾
    sns.heatmap(corr, mask=mask, annot=True, 
                fmt='.2f', cmap='coolwarm',
                vmin=-1, vmax=1, center=0)
    
    plt.title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
    return plt.gcf()
```

## 2. äº¤äº’å¼å¯è§†åŒ–

### 2.1 Plotlyä½¿ç”¨
```python
# ğŸ”„ å®æˆ˜æ¡ˆä¾‹ï¼šäº¤äº’å¼è®­ç»ƒç›‘æ§
import plotly.graph_objects as go
from plotly.subplots import make_subplots

def create_training_dashboard(history):
    """åˆ›å»ºè®­ç»ƒè¿‡ç¨‹äº¤äº’å¼ä»ªè¡¨æ¿"""
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('æŸå¤±æ›²çº¿', 'å‡†ç¡®ç‡æ›²çº¿', 
                       'å­¦ä¹ ç‡å˜åŒ–', 'æ¢¯åº¦èŒƒæ•°')
    )
    
    # æ·»åŠ æŸå¤±æ›²çº¿
    fig.add_trace(
        go.Scatter(y=history['loss'], name='è®­ç»ƒæŸå¤±'),
        row=1, col=1
    )
    fig.add_trace(
        go.Scatter(y=history['val_loss'], name='éªŒè¯æŸå¤±'),
        row=1, col=1
    )
    
    # æ·»åŠ å‡†ç¡®ç‡æ›²çº¿
    fig.add_trace(
        go.Scatter(y=history['accuracy'], name='è®­ç»ƒå‡†ç¡®ç‡'),
        row=1, col=2
    )
    fig.add_trace(
        go.Scatter(y=history['val_accuracy'], name='éªŒè¯å‡†ç¡®ç‡'),
        row=1, col=2
    )
    
    # æ·»åŠ å­¦ä¹ ç‡å˜åŒ–
    fig.add_trace(
        go.Scatter(y=history['lr'], name='å­¦ä¹ ç‡'),
        row=2, col=1
    )
    
    # æ·»åŠ æ¢¯åº¦èŒƒæ•°
    fig.add_trace(
        go.Scatter(y=history['gradient_norm'], name='æ¢¯åº¦èŒƒæ•°'),
        row=2, col=2
    )
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(height=800, showlegend=True,
                     title_text="æ¨¡å‹è®­ç»ƒç›‘æ§ä»ªè¡¨æ¿")
    
    return fig
```

### 2.2 Streamlitåº”ç”¨
```python
# ğŸ“± å®æˆ˜æ¡ˆä¾‹ï¼šæ¨¡å‹ç›‘æ§åº”ç”¨
import streamlit as st

def create_monitoring_app():
    """åˆ›å»ºStreamlitç›‘æ§åº”ç”¨"""
    st.title('AIæ¨¡å‹ç›‘æ§å¹³å°')
    
    # ä¾§è¾¹æ é…ç½®
    st.sidebar.header('é…ç½®')
    model_name = st.sidebar.selectbox(
        'é€‰æ‹©æ¨¡å‹',
        ['æ¨¡å‹A', 'æ¨¡å‹B', 'æ¨¡å‹C']
    )
    
    # ä¸»é¡µé¢
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader('æ¨¡å‹æ€§èƒ½æŒ‡æ ‡')
        metrics = get_model_metrics(model_name)
        st.metric('å‡†ç¡®ç‡', f"{metrics['accuracy']:.2%}")
        st.metric('F1åˆ†æ•°', f"{metrics['f1']:.2%}")
    
    with col2:
        st.subheader('é¢„æµ‹åˆ†å¸ƒ')
        fig = plot_prediction_distribution(model_name)
        st.plotly_chart(fig)
    
    # é¢„æµ‹å†å²
    st.subheader('é¢„æµ‹å†å²')
    history = get_prediction_history(model_name)
    st.line_chart(history)
```

## 3. å®éªŒç›‘æ§

### 3.1 TensorBoardä½¿ç”¨
```python
# ğŸ“ˆ å®æˆ˜æ¡ˆä¾‹ï¼šTensorBoardé›†æˆ
from torch.utils.tensorboard import SummaryWriter

class ModelTrainer:
    def __init__(self, model, log_dir='runs/experiment'):
        self.model = model
        self.writer = SummaryWriter(log_dir)
    
    def train_epoch(self, epoch, dataloader):
        """è®­ç»ƒä¸€ä¸ªepochå¹¶è®°å½•åˆ°TensorBoard"""
        for batch_idx, (data, target) in enumerate(dataloader):
            # å‰å‘ä¼ æ’­
            output = self.model(data)
            loss = self.criterion(output, target)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            # è®°å½•æŒ‡æ ‡
            self.writer.add_scalar('train/loss', 
                                 loss.item(), 
                                 epoch * len(dataloader) + batch_idx)
            
            # è®°å½•æ¢¯åº¦ç›´æ–¹å›¾
            for name, param in self.model.named_parameters():
                self.writer.add_histogram(f'gradients/{name}', 
                                        param.grad, 
                                        epoch)
    
    def log_model_graph(self, input_size):
        """è®°å½•æ¨¡å‹å›¾ç»“æ„"""
        dummy_input = torch.randn(input_size)
        self.writer.add_graph(self.model, dummy_input)
```

### 3.2 MLflowè·Ÿè¸ª
```python
# ğŸ“Š å®æˆ˜æ¡ˆä¾‹ï¼šMLflowå®éªŒè·Ÿè¸ª
import mlflow
import mlflow.pytorch

def train_with_mlflow(model, train_loader, valid_loader, 
                      num_epochs, hyperparameters):
    """ä½¿ç”¨MLflowè·Ÿè¸ªè®­ç»ƒå®éªŒ"""
    # è®¾ç½®å®éªŒ
    mlflow.set_experiment('æ¨¡å‹è®­ç»ƒå®éªŒ')
    
    # å¼€å§‹æ–°çš„è¿è¡Œ
    with mlflow.start_run():
        # è®°å½•è¶…å‚æ•°
        mlflow.log_params(hyperparameters)
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(num_epochs):
            # è®­ç»ƒ
            train_loss = train_epoch(model, train_loader)
            # éªŒè¯
            valid_loss = validate(model, valid_loader)
            
            # è®°å½•æŒ‡æ ‡
            mlflow.log_metrics({
                'train_loss': train_loss,
                'valid_loss': valid_loss
            }, step=epoch)
            
            # ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
            mlflow.pytorch.log_model(model, f'model_epoch_{epoch}')
            
            # è®°å½•å­¦ä¹ æ›²çº¿
            plot_learning_curves(train_loss, valid_loss)
            mlflow.log_artifact('learning_curves.png')
```

## å®æˆ˜é¡¹ç›®ï¼šAIå®éªŒç®¡ç†å¹³å°

### é¡¹ç›®æè¿°
å¼€å‘ä¸€ä¸ªå®Œæ•´çš„AIå®éªŒç®¡ç†å¹³å°ï¼Œé›†æˆå¯è§†åŒ–å’Œç›‘æ§åŠŸèƒ½ã€‚

### é¡¹ç›®ä»£ç æ¡†æ¶
```python
class ExperimentManager:
    def __init__(self):
        self.mlflow_client = mlflow.tracking.MlflowClient()
        self.tensorboard_writer = SummaryWriter('runs/current')
        
    def start_experiment(self, name, config):
        """å¯åŠ¨æ–°å®éªŒ"""
        mlflow.set_experiment(name)
        with mlflow.start_run() as run:
            # è®°å½•é…ç½®
            mlflow.log_params(config)
            return run.info.run_id
    
    def log_metrics(self, metrics, step):
        """è®°å½•æŒ‡æ ‡"""
        # MLflowè®°å½•
        mlflow.log_metrics(metrics, step=step)
        
        # TensorBoardè®°å½•
        for name, value in metrics.items():
            self.tensorboard_writer.add_scalar(name, value, step)
    
    def log_model(self, model, artifacts):
        """è®°å½•æ¨¡å‹å’Œç›¸å…³æ–‡ä»¶"""
        # ä¿å­˜æ¨¡å‹
        mlflow.pytorch.log_model(model, 'model')
        
        # ä¿å­˜ç›¸å…³æ–‡ä»¶
        for name, artifact in artifacts.items():
            mlflow.log_artifact(artifact, name)
    
    def create_dashboard(self):
        """åˆ›å»ºå®éªŒä»ªè¡¨æ¿"""
        # ä½¿ç”¨Streamlitåˆ›å»ºWebç•Œé¢
        st.title('AIå®éªŒç®¡ç†å¹³å°')
        
        # æ˜¾ç¤ºå®éªŒåˆ—è¡¨
        experiments = self.mlflow_client.list_experiments()
        selected_exp = st.sidebar.selectbox(
            'é€‰æ‹©å®éªŒ',
            [exp.name for exp in experiments]
        )
        
        # æ˜¾ç¤ºå®éªŒè¯¦æƒ…
        runs = self.mlflow_client.search_runs(
            experiment_ids=[selected_exp]
        )
        st.write('å®éªŒè¿è¡Œå†å²ï¼š')
        st.dataframe(runs)
```

## ç»ƒä¹ ä¸ä½œä¸š
1. åˆ›å»ºæ¨¡å‹è®­ç»ƒå¯è§†åŒ–
2. æ­å»ºå®éªŒè·Ÿè¸ªç³»ç»Ÿ
3. å¼€å‘ç›‘æ§ä»ªè¡¨æ¿

## æ‰©å±•é˜…è¯»
- [Matplotlibæ•™ç¨‹](https://matplotlib.org/stable/tutorials/index.html)
- [Plotlyæ–‡æ¡£](https://plotly.com/python/)
- [MLflowæŒ‡å—](https://www.mlflow.org/docs/latest/index.html)

## å°æµ‹éªŒ
1. å¦‚ä½•é€‰æ‹©åˆé€‚çš„å¯è§†åŒ–ç±»å‹ï¼Ÿ
2. å®éªŒè·Ÿè¸ªç³»ç»Ÿçš„å…³é”®è¦ç´ æ˜¯ä»€ä¹ˆï¼Ÿ
3. å¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„ç›‘æ§æŒ‡æ ‡ï¼Ÿ

## ä¸‹ä¸€æ­¥å­¦ä¹ 
- æ¨¡å‹éƒ¨ç½²
- è‡ªåŠ¨åŒ–æµ‹è¯•
- æ€§èƒ½ä¼˜åŒ–

## å¸¸è§é—®é¢˜è§£ç­”
Q: å¦‚ä½•é€‰æ‹©å¯è§†åŒ–å·¥å…·ï¼Ÿ
A: æ ¹æ®éœ€æ±‚é€‰æ‹©ï¼šé™æ€åˆ†æç”¨Matplotlib/Seabornï¼Œäº¤äº’å¼å±•ç¤ºç”¨Plotlyï¼Œå¿«é€ŸåŸå‹ç”¨Streamlitã€‚

Q: å¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„ç›‘æ§ç³»ç»Ÿï¼Ÿ
A: å…³æ³¨å…³é”®æŒ‡æ ‡ï¼Œè®¾ç½®åˆç†çš„å‘Šè­¦é˜ˆå€¼ï¼Œä¿æŒå¯è§†åŒ–çš„ç›´è§‚æ€§ï¼Œæ”¯æŒå®æ—¶æ›´æ–°ã€‚
